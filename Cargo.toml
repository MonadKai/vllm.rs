[package]
name = "vllm-rs"
version = "0.1.0"
edition = "2021"

[dependencies]
candle-core = { git = "https://github.com/guoqingbao/candle.git", version = "0.8.3", rev = "31b2025" }
candle-nn = { git = "https://github.com/guoqingbao/candle.git", version = "0.8.3", rev = "31b2025" }
serde = { version = "1.0.190", features = ["serde_derive"] }
tokenizers = {version = "0.21.1", features = ["http"] }
candle-transformers = { git = "https://github.com/guoqingbao/candle.git", version = "0.8.3", rev = "31b2025" }
hf-hub = "0.4.1"
anyhow = "1.0.75"
itertools = "0.13.0"
akin = "0.4.0"
indicatif = "0.17.11"
serde_json = "1.0.108"
#cudarc = {version = "0.13.9", features = ["f16", "cuda-version-from-build-system"], optional = true }
half = { version = "2.5.0", features = ["num-traits", "use-intrinsics", "rand_distr"] }
tokio = { version = "1.38.0", features = ["sync"] }
tracing = "0.1.40"
tracing-subscriber = { version = "0.3.18", features = ["env-filter"] }
either = { version = "1.13.0", features = ["serde"] }
minijinja = { version = "2.10.2", features = ["builtins", "json"] }
minijinja-contrib = { version = "2.10.2", features = ["pycompat"] }
lazy_static = {version = "1.4.0"}
interprocess = "2.2.2"
serde-big-array = "0.5.1"
bincode = { version = "1.3.1" }
twox-hash = "2.1.1"
rand = "0.9.0"
rayon="1.10.0"
clap = { version = "4.4.7", features = ["derive"] }
thiserror = "1.0.58"
attention-rs = {git = "https://github.com/guoqingbao/attention.rs.git", version="0.1.0", rev = "e546362" }

[features]
cuda = ["candle-core/cuda", "candle-nn/cuda", "candle-transformers/cuda", "attention-rs/cuda", "attention-rs/flash-attn"]
metal = ["candle-core/metal", "candle-nn/metal", "candle-transformers/metal", "attention-rs/metal"]